{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhrubanka/.local/lib/python3.7/site-packages/bigdl/util/engine.py:41: UserWarning: Find both SPARK_HOME and pyspark. You may need to check whether they match with each other. SPARK_HOME environment variable is set to: /opt/apache-spark, and pyspark is found in: /home/dhrubanka/.local/lib/python3.7/site-packages/pyspark/__init__.py. If they are unmatched, please use one source only to avoid conflict. For example, you can unset SPARK_HOME and use pyspark only.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepending /home/dhrubanka/.local/lib/python3.7/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dhrubanka/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%pylab inline \n",
    "import pandas\n",
    "import datetime as dt\n",
    "\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.dataset import mnist\n",
    "from pyspark import SparkContext\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from bigdl.transform.vision.image import *\n",
    "\n",
    "import numpy as np # needed for reshaping binary image data \n",
    "import tensorflow as tf # needed to implement classifier\n",
    "\n",
    "# suppress tensorflow warnings to keep clean\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=create_spark_conf().setMaster(\"local[4]\").set(\"spark.driver.memory\",\"2g\"))\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions to classify images'''\n",
    "\n",
    "\n",
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def read_tensor_from_image_file(image,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "#   input_image = cv2.imread(file_name)\n",
    "    img2= cv2.resize(image,dsize=(input_height,input_width), interpolation = cv2.INTER_CUBIC)\n",
    "#Numpy array\n",
    "    np_image_data = np.asarray(img2)\n",
    "  #maybe insert float convertion here - see edit remark!\n",
    "    np_final = np.expand_dims(np_image_data,axis=0)\n",
    "    normalized = tf.divide(tf.subtract(np_final, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "def predict(graph, input_operation, output_operation, t):\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "        })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "    top_k = results.argsort()[-5:][::-1]\n",
    "    labels = load_labels(label_file)\n",
    "    return [top_k, labels, results]\n",
    "\n",
    "# Defining model parameters \n",
    "model_file = \"brain_tumor_weights/output_graph.pb\"\n",
    "label_file = \"brain_tumor_weights/output_labels.txt\"\n",
    "input_height = 299\n",
    "input_width = 299\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "input_layer = \"Mul\"\n",
    "output_layer = \"final_result\"\n",
    "\n",
    "# Loading graph beforehand\n",
    "graph = load_graph(model_file)\n",
    "\n",
    "# Setting name and input parameters beforehand\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000000  Tumor Prediction:  no\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000001  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000002  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000003  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000004  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000005  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000006  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000007  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000008  Tumor Prediction:  yes\n",
      "Image:  hdfs://localhost:9000/lsdp_project/brain_cancer_dataset/2.8Gb Dignosis for Cancer_DOI_R_004_1.3.6.1.4.1.14519.5.2.1.4320.5030.248552508121514040263344871813_1.3.6.1.4.1.14519.5.2.1.4320.5030.966354075876482042295761929295_000009  Tumor Prediction:  yes\n"
     ]
    }
   ],
   "source": [
    "# load the hadoop filesystem into pyspark context\n",
    "\n",
    "hadoop = sc._jvm.org.apache.hadoop\n",
    "fs = hadoop.fs.FileSystem\n",
    "conf = hadoop.conf.Configuration()\n",
    "\n",
    "# give dataset path to pyspark context\n",
    "path = hadoop.fs.Path('/lsdp_project/brain_cancer_dataset')\n",
    "\n",
    "# initalize empty list \n",
    "file_predicitons = []\n",
    "\n",
    "# count to check if all files accessed : around 4682\n",
    "count = 0\n",
    "\n",
    "for f in fs.get(conf).listStatus(path):\n",
    "    \n",
    "    # get the path of each binary file\n",
    "    image_file_path = f.getPath()\n",
    "    image_file_path = f.getPath()\n",
    "#     print(image_file_path)\n",
    "    \n",
    "    # load binary file into variable\n",
    "    wc = SparkContext.binaryFiles(sc, path = str(image_file_path), minPartitions=None)\n",
    "    list_elements = wc.collect()\n",
    "    image_bytes = list_elements[0][1]\n",
    "    \n",
    "    # form back image from bytes \n",
    "    recovered_image = np.frombuffer(image_bytes,dtype='uint8').reshape(512,512,3)\n",
    "    \n",
    "    # load tensor for the image file into variable\n",
    "    t = read_tensor_from_image_file(\n",
    "        recovered_image,\n",
    "        input_height=input_height,\n",
    "        input_width=input_width,\n",
    "        input_mean=input_mean,\n",
    "        input_std=input_std)\n",
    "    \n",
    "    # get predictions from the model \n",
    "    top_k, labels, results = predict(graph, input_operation,output_operation,t)\n",
    "    prediction_label = labels[top_k[0]]\n",
    "    \n",
    "    # append file,predicition to list\n",
    "    file_predicitons.append((str(image_file_path),prediction_label))\n",
    "    count += 1\n",
    "    \n",
    "    print('Image: ',str(image_file_path),' Tumor Prediction: ',prediction_label)\n",
    "    \n",
    "    if count==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open('classification_results.pkl', 'wb') as f:\n",
    "    pickle.dump(file_predicitons, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
